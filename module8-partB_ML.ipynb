{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - ML, XAI, and data analytics\n",
    "\n",
    "## Machine Learning - Neural Networks Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:21:38.071880Z",
     "start_time": "2020-07-05T18:21:33.683563Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Numerical Data Manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "\n",
    "\n",
    "# Naive Bayes libraries\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB      # Naive Bayes Classifier based on a Bernoulli Distribution\n",
    "from sklearn.naive_bayes import GaussianNB       # Naive Bayes Classifier based on a Gaussian Distribution\n",
    "from sklearn.naive_bayes import MultinomialNB    # Naive Bayes Classifier based on a Multinomial Distribution\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Text Analysis libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:21:38.088359Z",
     "start_time": "2020-07-05T18:21:38.082473Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict( model, image, print_img ):\n",
    "    \n",
    "    if( print_img ):\n",
    "        plt.grid(b=None)\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    n_image = np.expand_dims(image, axis=0)\n",
    "    n_image = np.expand_dims(n_image, axis=3)\n",
    "    \n",
    "    prediction = model.predict( n_image )[0]\n",
    "    \n",
    "    if( prediction >= 0.5 ):\n",
    "        if( print_img ):\n",
    "            print('Model Prediction: CRIMINAL with probability = %.2f' % prediction)\n",
    "        result = 1\n",
    "    else:\n",
    "        if( print_img ):\n",
    "            print('Model Prediction: NOT CRIMINAL with probability = %.2f' % prediction)\n",
    "        result = 0\n",
    "        \n",
    "    return result\n",
    "\n",
    "def check_image_dataset( dataset, class_var ):\n",
    "    \n",
    "    last_pixels = dataset[[\"pixel_4092\", \"pixel_4093\", \"pixel_4094\", \"pixel_4095\", class_var]]\n",
    "    return last_pixels\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the workshop, we will see how we can apply the principles of Deep Learning to more complex datasets, like images.\n",
    "\n",
    "Let's suppose that we have a dataset with faces of people with / and without crimial records. Like the paper that was presented in last workshop, we are going to try to use a very simple neural network to try to find patterns in faces that are considered criminals from those who are not.\n",
    "\n",
    "Note: this is a toy dataset. It does not represent any reality. We collected a public research dataset with human faces and randomly labelled them as *Criminal* and *Not Criminal* for learning purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:21:42.918703Z",
     "start_time": "2020-07-05T18:21:41.550211Z"
    }
   },
   "outputs": [],
   "source": [
    "faces_dataset = pd.read_csv('data/dataset_64_v2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:21:43.328193Z",
     "start_time": "2020-07-05T18:21:43.314841Z"
    }
   },
   "outputs": [],
   "source": [
    "faces_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:21:45.233412Z",
     "start_time": "2020-07-05T18:21:45.229828Z"
    }
   },
   "outputs": [],
   "source": [
    "# total number of images in dataset:\n",
    "num_images = len(faces_dataset)\n",
    "num_pixels = len(faces_dataset.columns) - 1\n",
    "\n",
    "print('Total number of images in the dataset is: ' + str(num_images))\n",
    "print('Total number of pixels per image is: ' + str(num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:21:46.521623Z",
     "start_time": "2020-07-05T18:21:46.469042Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can also try to understand what is the distribution of criminals / not crimials in our dataset:\n",
    "criminals = faces_dataset[ faces_dataset['target'] == 1 ]\n",
    "not_criminals = faces_dataset[ faces_dataset['target'] == 0 ]\n",
    "\n",
    "print('Criminality distribution:')\n",
    "print('Number of criminals: ' + str(len(criminals)))\n",
    "print('Number of not criminals: ' + str(len(not_criminals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a set of pixels. More precesely, each image corresponds to a row and each image contains a total of 9216 pixels. This means that the image has a size of 96x96. The last colum **target** specifies if the face is associated to someone who has crimial records *target=1* or to someone who does not have any crminal records *target=0*.\n",
    "\n",
    "Let's see if we can visualize the images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:22:03.684189Z",
     "start_time": "2020-07-05T18:22:03.463926Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting some images... \n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "indx = 1\n",
    "image_0 = faces_dataset.iloc[indx,0:num_pixels]\n",
    "\n",
    "# image_0 is a vector with 9216 pixels. In order to convert it into an image,\n",
    "# we need to reshape this vector into a matrix of 96*96 = 9216 pixels\n",
    "\n",
    "image_0 =  np.array(image_0)\n",
    "image_0 = np.reshape(image_0, (64, 64))\n",
    "image_0 = resize(image_0, (128, 128), anti_aliasing=True)\n",
    "\n",
    "# show image\n",
    "plt.imshow(image_0,  cmap=plt.cm.gray )\n",
    "\n",
    "# print target\n",
    "if( faces_dataset.iloc[indx,num_pixels] == 1):\n",
    "    print('Image label = CRIMINAL')\n",
    "else:\n",
    "    print('Image label = NOT CRIMINAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach we are going to use for facial recognition is very straight forward but you could check this out in the case of a very complicated problem. Let’s learn how modern face recognition works!\n",
    "\n",
    "The goal here is to get deep neural network to output a person’s face with identification. This means that the neural network needs to be trained to automatically identify different features of a face and calculate numbers based on that. The output of the neural network can be thought of as an identifier for a particular person's face: in this case, if the person represents a criminal or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, a Convolutional Neural Network (CNN or ConvNet) is a class of artificial neural networks that has successfully been applied to analyzing visual imagery. They have applications in image recognition (facial recognition) and video analysis, recommender systems and natural language processing. Here, facial recognition would be analysed.\n",
    "\n",
    "The name *convolutional* comes preisely from a mathematical operation that is called the *convolution operator*. This operator is able to convolute an image based on a kernel, which can detect vertical edges, horizontal edges,faces, eyes, etc. The following figure shows an example of a convolution:\n",
    "\n",
    "<img src='https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/keras-conv2d/keras_conv2d_padding.gif' />\n",
    "A 3×3 kernel applied to an image. This animation was contributed to StackOverflow (<a href=\"https://stackoverflow.com/questions/52067833/how-to-plot-an-animated-matrix-in-matplotlib\">source</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:22:55.712876Z",
     "start_time": "2020-07-05T18:22:55.076228Z"
    }
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "\n",
    "WIDTH = 64\n",
    "HEIGHT = 64\n",
    "\n",
    "data = faces_dataset.iloc[:,0:num_pixels]\n",
    "for indx in range(0, len(data)):\n",
    "    \n",
    "    image = np.array(data.iloc[indx,0:num_pixels])\n",
    "    # normalise pixels\n",
    "    temp = np.reshape(image, (WIDTH, HEIGHT))/255.0\n",
    "    all_images.append(temp)\n",
    "\n",
    "# convert structure to array\n",
    "all_images = np.array(all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:22:56.765947Z",
     "start_time": "2020-07-05T18:22:56.719495Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate your dataset: \n",
    "# put the variable that you wish to classify (the target) in one variable\n",
    "# put your features (the pixels) in another variable\n",
    "X=np.zeros((num_images,WIDTH,HEIGHT,1))\n",
    "X[:,:,:,0]=all_images\n",
    "y = faces_dataset.iloc[:,num_pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:22:58.242051Z",
     "start_time": "2020-07-05T18:22:58.200828Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate the dataset into test set and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many layers that can be used in deep learning networks.\n",
    "In image data, we use convolutional layers, and to avoid overfitting, we use MaxPooling and Dropout. \n",
    "Very generaly, MaxPooling is a way to reduce the size of your image through a process of discretization.\n",
    "The Dropout layer corresponds to a random discard of data. This is good, because deep neural networks tend to overfit (or learn the training data by heart). By discarding training elements randomly, we are helping to reduce the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:22:59.925431Z",
     "start_time": "2020-07-05T18:22:59.685507Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model_deep = Sequential()\n",
    "\n",
    "# add layers\n",
    "model_deep.add(Conv2D(64, (3, 3), padding = 'same', activation='relu', input_shape=(WIDTH, HEIGHT, 1)))\n",
    "model_deep.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_deep.add(Dropout(0.25))\n",
    "\n",
    "model_deep.add(Conv2D(32, (3, 3), padding = 'same', activation='relu', input_shape=(WIDTH, HEIGHT, 1)))\n",
    "model_deep.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_deep.add(Dropout(0.25))\n",
    "model_deep.add(Flatten())\n",
    "\n",
    "model_deep.add(Dense(256, activation='tanh'))\n",
    "\n",
    "model_deep.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:00.948758Z",
     "start_time": "2020-07-05T18:23:00.943637Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualise the model\n",
    "model_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:02.573397Z",
     "start_time": "2020-07-05T18:23:01.775713Z"
    }
   },
   "outputs": [],
   "source": [
    "# another way of visualising the network\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "plot_model(model_deep, \"model_dnn.png\", show_shapes=True, show_layer_names=False, rankdir='TB', dpi=150)\n",
    "img = mpimg.imread(\"model_dnn.png\")\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.axis('off');\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:04.699862Z",
     "start_time": "2020-07-05T18:23:04.675524Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "# SGD = Stochastic Gradient Descent\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_deep.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:48.534282Z",
     "start_time": "2020-07-05T18:23:06.496884Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "history_deep = model_deep.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:50.437854Z",
     "start_time": "2020-07-05T18:23:49.195360Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc_deep = model_deep.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc_deep = model_deep.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc_deep, test_acc_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:51.223844Z",
     "start_time": "2020-07-05T18:23:51.057623Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history_deep.history['accuracy'], label='train')\n",
    "pyplot.plot(history_deep.history['val_accuracy'], label='test')\n",
    "pyplot.ylabel('accuracy', fontsize=12)\n",
    "pyplot.xlabel('iterations', fontsize=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:52.071860Z",
     "start_time": "2020-07-05T18:23:51.830017Z"
    }
   },
   "outputs": [],
   "source": [
    "indx = 0\n",
    "image = all_images[indx,:,:]\n",
    "predict( model_deep, image, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:23:52.908644Z",
     "start_time": "2020-07-05T18:23:52.705052Z"
    }
   },
   "outputs": [],
   "source": [
    "indx = 1\n",
    "image = all_images[indx,:,:]\n",
    "predict( model_deep, image, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing, but without using the convolutional networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make an analysis of your results in terms of different evaluation metrics by calling the function *classification_report*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:24:05.267792Z",
     "start_time": "2020-07-05T18:23:53.506717Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "results = []\n",
    "for indx in range(0, len(X_test)):\n",
    "    \n",
    "    image = X_test[indx,:,:,0]\n",
    "    r = predict( model_deep, image, False )\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:24:05.889264Z",
     "start_time": "2020-07-05T18:24:05.878683Z"
    }
   },
   "outputs": [],
   "source": [
    "names=['NOT CRIMINAL', 'CRIMINAL']\n",
    "print(classification_report(y_test.values, results, target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visuallize this, using the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:24:06.676683Z",
     "start_time": "2020-07-05T18:24:06.505004Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, results)\n",
    "sns.heatmap(mat.T, square=True, fmt='d', cbar=True, xticklabels=names, \\\n",
    "            yticklabels=names, annot=True)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at some pixels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:24:07.269935Z",
     "start_time": "2020-07-05T18:24:07.261758Z"
    }
   },
   "outputs": [],
   "source": [
    "last_pixels = check_image_dataset( faces_dataset, \"target\" )\n",
    "\n",
    "# and let's separate between CRIMINAL taget = 1 ...\n",
    "criminal_last_pixels = last_pixels[ last_pixels[\"target\"] == 1 ]\n",
    "criminal_last_pixels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T18:24:07.873666Z",
     "start_time": "2020-07-05T18:24:07.864509Z"
    }
   },
   "outputs": [],
   "source": [
    "# ... and NOT CRIMINAL target = 0\n",
    "ncriminal_last_pixels = last_pixels[ last_pixels[\"target\"] == 0 ]\n",
    "ncriminal_last_pixels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you think about this?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Discussion:\n",
    "\n",
    "- Q1. What is the major problem with the design of this model?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- Q2. What are the major consequences of the application of this model if people use it as a black box?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- Q3. How could we do this correctly?\n",
    "\n",
    "**Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
